{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8s0nL4HJXiK"
      },
      "source": [
        "# Assigmnet 1\n",
        "\n",
        "<hr>\n",
        "\n",
        "In this assignment , construct the [GoogleNet](https://arxiv.org/abs/1409.4842)/Inception architecture reconstructed from scratch for fit outdata as outlined. This entails creating a neural network model that proved successful in the ILSVRC 2014 competition. The objective is to train this model on the FashionMNIST dataset, a collection of grayscale images depicting fashion items, encompassing various categories like shoes and clothing.\n",
        "\n",
        "To ensure optimal model training, it is imperative to implement data normalization. This involves adjusting the pixel values of the images to a standardized range, promoting convergence during training. Additionally, PyTorch data loader implementation is necessary for efficient handling of the dataset, enabling seamless batch processing.\n",
        "\n",
        "During the training phase, employ the Adam optimizer, a widely used optimization algorithm, with a learning rate set at 0.01. Training should span minimum of 50 epochs, each epoch representing a full iteration through the dataset. This extended training duration aims to enhance the ability of the model to discern patterns and features within the FashionMNIST dataset.\n",
        "\n",
        "To evaluate the performance of the model, plot both the training and test error loss. These plots serve as visual indicators of the learning progress and generalization capabilities of the model.  Analyzing these curves can offer insights into potential adjustments or improvements needed in the model architecture or training parameters.\n",
        "\n",
        "Lastly, for  ease of access, save the completed notebook to your Google Drive. Once the assignment is finished, share the notebook with mesfin.diro@aau.edu.et via Colab.\n",
        "\n",
        "<hr>\n",
        "\n",
        "20%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxZT0QAwPAWL"
      },
      "source": [
        "## Tip: Use GPU Acceleration\n",
        "\n",
        "To running this notebook in Google Colab with GPU, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNnjo-cbPaYE"
      },
      "source": [
        "Let's make sure that we have access to GPU. We can use nvidia-smi command to do that. In case of any problems navigate to Edit -> Notebook settings -> Hardware accelerator, set it to GPU, and then click Save."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGNdphZMPdQb",
        "outputId": "8c0f18e4-8230-41da-9a15-e00415a6aa77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 28 11:14:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6I4NbvdPvSI"
      },
      "source": [
        "## Explore the current directory on your colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5owiHU-P74H",
        "outputId": "c80f3a33-aa9c-4137-83ba-b037b1de7580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsJlbeMgQEcl",
        "outputId": "1ca2c2a4-4303-4ec5-f42a-38f373b15145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z7Osn8mnOKtV"
      },
      "outputs": [],
      "source": [
        "#!pip install package\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "from torchvision.models import Inception3\n",
        "import torch.nn.functional as F\n",
        "sns.reset_orig()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IsyjDoEdoviG"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5),\n",
        "                          (0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JxD2X4ApoviI"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.FashionMNIST(root='./FM_train_data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./FM_test_data', train=False,\n",
        "                                       download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "775g3C-VoviK"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coUS-syxOfQB",
        "outputId": "be86c810-a9f9-417e-e0a7-e9f724bbf29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \".\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \".\"\n",
        "\n",
        "# Function for setting the seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GYSv5RX7JIoY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define InceptionNet model\n",
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(InceptionNet, self).__init__()\n",
        "        # Load the pre-trained Inception v3 model without the auxiliary logits\n",
        "        self.inception = Inception3(num_classes=num_classes, aux_logits=False)\n",
        "        # Modify the first convolution layer to accept 1 channel instead of 3 ( for channel 1 image)\n",
        "        self.inception.Conv2d_1a_3x3.conv = nn.Conv2d(1, 32, kernel_size=3, stride=2, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Transform the input to meet Inception v3 requirements\n",
        "        x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "        # Forward pass through Inception v3\n",
        "        return self.inception(x)\n",
        "\n",
        "#Initialize the InceptionNet model\n",
        "model = InceptionNet(num_classes=10)\n",
        "model = model.to(\"cuda\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "u_c2K3NtoviQ"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define the number of training epochs\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "romT1j1RoviT",
        "outputId": "4bc753da-09fb-41f2-a494-26108a65452f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ca3d92890510>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize lists to store loss and accuracy values\n",
        "train_loss = []\n",
        "train_accuracy = []\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # Calculate epoch loss and accuracy\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    epoch_accuracy = correct / total\n",
        "\n",
        "    # Append loss and accuracy values to the lists\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_accuracy.append(epoch_accuracy)\n",
        "\n",
        "    # Print the current loss after every epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "# Plot the training loss\n",
        "plt.plot(train_loss)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Plot the training accuracy\n",
        "plt.plot(train_accuracy)\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmReS7ZloviX"
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXrDNGP4oviZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}